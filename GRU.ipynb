{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Package installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: snowballstemmer in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (2.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (0.0.post11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: torch in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (2.1.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (4.4.0)\n",
      "Requirement already satisfied: sympy in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (1.5.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.8.1->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement string (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for string\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement sys (from versions: none)\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[31mERROR: No matching distribution found for sys\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting argparse\n",
      "  Using cached argparse-1.4.0-py2.py3-none-any.whl (23 kB)\n",
      "Installing collected packages: argparse\n",
      "Successfully installed argparse-1.4.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: sklearn in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (0.0.post11)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (4.3.2)\n",
      "Requirement already satisfied: nltk in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (3.8.1)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from gensim) (6.4.0)\n",
      "Requirement already satisfied: click in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from nltk) (1.3.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from nltk) (2023.10.3)\n",
      "Requirement already satisfied: tqdm in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from nltk) (4.66.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: gensim in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (4.3.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from gensim) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.7.0 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from gensim) (1.11.3)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from gensim) (6.4.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: keras in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (2.14.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: matplotlib in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (3.8.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from matplotlib) (4.44.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (22.0)\n",
      "Requirement already satisfied: pillow>=8 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (9.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: stanza in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (1.6.1)\n",
      "Requirement already satisfied: emoji in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from stanza) (2.8.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stanza) (1.23.5)\n",
      "Requirement already satisfied: protobuf>=3.15.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stanza) (4.21.11)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from stanza) (2.28.1)\n",
      "Requirement already satisfied: torch>=1.3.0 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from stanza) (2.1.0)\n",
      "Requirement already satisfied: tqdm in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from stanza) (4.66.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (3.8.0)\n",
      "Requirement already satisfied: typing-extensions in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (4.4.0)\n",
      "Requirement already satisfied: sympy in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from torch>=1.3.0->stanza) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from torch>=1.3.0->stanza) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from torch>=1.3.0->stanza) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from torch>=1.3.0->stanza) (2023.10.0)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->stanza) (2.1.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->stanza) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->stanza) (1.26.13)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from requests->stanza) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages (from jinja2->torch>=1.3.0->stanza) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/thzaamoun/Library/Python/3.11/lib/python/site-packages (from sympy->torch>=1.3.0->stanza) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install snowballstemmer\n",
    "%pip install torch\n",
    "%pip install pandas\n",
    "%pip install string\n",
    "%pip install sys\n",
    "%pip install argparse\n",
    "%pip install sklearn\n",
    "%pip install gensim nltk\n",
    "%pip install gensim\n",
    "%pip install keras\n",
    "%pip install matplotlib\n",
    "%pip install stanza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Positive</td>\n",
       "      <td>ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Positive</td>\n",
       "      <td>أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Positive</td>\n",
       "      <td>هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Positive</td>\n",
       "      <td>خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Positive</td>\n",
       "      <td>ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text\n",
       "0  Positive  ممتاز نوعا ما . النظافة والموقع والتجهيز والشا...\n",
       "1  Positive  أحد أسباب نجاح الإمارات أن كل شخص في هذه الدول...\n",
       "2  Positive  هادفة .. وقوية. تنقلك من صخب شوارع القاهرة الى...\n",
       "3  Positive  خلصنا .. مبدئيا اللي مستني ابهار زي الفيل الاز...\n",
       "4  Positive  ياسات جلوريا جزء لا يتجزأ من دبي . فندق متكامل..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/thzaamoun/Desktop/Academia/Fall 23/NLP/Assignment 2/VSCODE/ar_reviews_100k.tsv',sep='\\t')\n",
    "reviews = df['text']  # Replace with your actual column name\n",
    "labels = df['label']    # Replace with your actual label column name\n",
    "# First, shuffle the DataFrame\n",
    "df_shuffled = shuffle(df, random_state=42)\n",
    "\n",
    "#Sample 20% of the dataframe\n",
    "df_sampled = df_shuffled.sample(frac=1, random_state=42)  # frac=0.2 means 20%\n",
    "\n",
    "# Then, split the features and labels\n",
    "X = df_sampled['text'].values\n",
    "y = df_sampled['label'].values\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # There is no need to remove diacretics since thery are already not there\n",
    "    # Remove special characters and numbers\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    return text\n",
    "\n",
    "reviews = reviews.apply(clean_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization + Stopword removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snowballstemmer import stemmer\n",
    "\n",
    "# Create an Arabic stemmer\n",
    "ar_stemmer = stemmer(\"arabic\")\n",
    "\n",
    "# Define a function to stem each word in a given text\n",
    "def stem_text(text):\n",
    "    words = text.split()\n",
    "    stemmed_words = [ar_stemmer.stemWord(word) for word in words]\n",
    "    return ' '.join(stemmed_words)\n",
    "\n",
    "# Apply the function to each text entry in the Series\n",
    "reviews = reviews.apply(stem_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     ممتاز نوع ما نظاف والموقع والتجهيز والشاطيء مطعم\n",
       "1    احد اسباب نجاح امار ان كل شخص في هذه دول يعشق ...\n",
       "2    هادف وقو تنقل من صخب شوارع قاهر الي هدوء جبال ...\n",
       "3    خلص مبديي الل مست ابهار زي فيل ازرق ميقراش احس...\n",
       "4    ياسا جلوري جزء لا يتجزء من دب ندق متكامل خدم م...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = reviews.apply(lambda x: word_tokenize(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def build_vocab(sentences, min_word_freq):\n",
    "    # Count word frequencies\n",
    "    word_freq = Counter(word for sentence in sentences for word in sentence)\n",
    "    \n",
    "    # Remove words below a certain frequency\n",
    "    word_freq = {word: freq for word, freq in word_freq.items() if freq >= min_word_freq}\n",
    "\n",
    "    # Build the vocabulary\n",
    "    vocab = {word: index + 2 for index, word in enumerate(word_freq)} # +2 for special tokens\n",
    "    vocab['<PAD>'] = 0  # Add a padding token\n",
    "    vocab['<UNK>'] = 1  # Add an unknown token\n",
    "\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(reviews, min_word_freq=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text-To-Sequence Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_to_sequence(sentences, vocab):\n",
    "    sequences = []\n",
    "    for sentence in sentences:\n",
    "        seq = [vocab.get(word, vocab['<UNK>']) for word in sentence]\n",
    "        sequences.append(seq)\n",
    "    return sequences\n",
    "\n",
    "sequences = text_to_sequence(reviews, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Padding Sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-15 21:46:10.532291: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_seq_length = 100  # Define based on your dataset\n",
    "sequences_padded = pad_sequences(sequences, maxlen=max_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(sequences_padded, labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "int32\n",
      "int32\n",
      "object\n",
      "object\n"
     ]
    }
   ],
   "source": [
    "print(X_train.dtype)\n",
    "print(X_test.dtype)\n",
    "print(y_train.dtype)\n",
    "print(y_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Sequence-Lists to Numpy Arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_seq_length = 100\n",
    "X_train_padded = pad_sequences(X_train, maxlen=max_seq_length, padding='post', dtype='int64')\n",
    "X_test_padded = pad_sequences(X_test, maxlen=max_seq_length, padding='post', dtype='int64')\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_data = torch.tensor(X_train_padded, dtype=torch.long)\n",
    "test_data = torch.tensor(X_test_padded, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encoding Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thzaamoun/Library/Python/3.11/lib/python/site-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import torch\n",
    "\n",
    "# Assuming y_train and y_test are your label arrays\n",
    "# Replace these with your actual data\n",
    "# y_train = [...]\n",
    "# y_test = [...]\n",
    "\n",
    "# Check for the presence of ellipsis or other unusual data types\n",
    "for item in np.concatenate([y_train.flatten(), y_test.flatten()]):\n",
    "    if isinstance(item, type(...)) or not isinstance(item, (str, int, float)):\n",
    "        print(\"Unusual item found:\", item)\n",
    "\n",
    "# Replace ellipsis with a standard string (e.g., 'Unknown')\n",
    "y_train = np.array(['Unknown' if isinstance(item, type(...)) else item for item in y_train.flatten()])\n",
    "y_test = np.array(['Unknown' if isinstance(item, type(...)) else item for item in y_test.flatten()])\n",
    "\n",
    "# Reshape back to 2D after replacement\n",
    "y_train = y_train.reshape(-1, 1)\n",
    "y_test = y_test.reshape(-1, 1)\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Fit and transform the training data\n",
    "y_train_encoded = onehot_encoder.fit_transform(y_train)\n",
    "\n",
    "# Transform the test data using the same encoder\n",
    "y_test_encoded = onehot_encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting to Pytorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "train_data = torch.tensor(X_train, dtype=torch.long)\n",
    "test_data = torch.tensor(X_test, dtype=torch.long)\n",
    "train_labels = torch.tensor(y_train_encoded, dtype=torch.float32)\n",
    "test_labels = torch.tensor(y_test_encoded, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data shape: torch.Size([79999, 100])\n",
      "Train labels shape: torch.Size([79999, 3])\n",
      "Test data shape: torch.Size([20000, 100])\n",
      "Test labels shape: torch.Size([20000, 3])\n"
     ]
    }
   ],
   "source": [
    "# Check the shapes of the datasets\n",
    "print(\"Train data shape:\", train_data.shape)\n",
    "print(\"Train labels shape:\", train_labels.shape)\n",
    "print(\"Test data shape:\", test_data.shape)\n",
    "print(\"Test labels shape:\", test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape: torch.Size([79999, 100])\n",
      "train_labels shape: torch.Size([79999, 3])\n",
      "test_data shape: torch.Size([20000, 100])\n",
      "test_labels shape: torch.Size([20000, 3])\n",
      "Adjusted train_data shape: torch.Size([79999, 100])\n",
      "Adjusted test_data shape: torch.Size([20000, 100])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Assuming train_data, train_labels, test_data, and test_labels are defined\n",
    "# Check the shapes\n",
    "print(\"train_data shape:\", train_data.shape)\n",
    "print(\"train_labels shape:\", train_labels.shape)\n",
    "print(\"test_data shape:\", test_data.shape)\n",
    "print(\"test_labels shape:\", test_labels.shape)\n",
    "\n",
    "# Correcting the mismatch\n",
    "# Trim train_data to match the size of train_labels\n",
    "if train_data.shape[0] > train_labels.shape[0]:\n",
    "    train_data = train_data[:train_labels.shape[0]]\n",
    "\n",
    "# Trim test_data to match the size of test_labels\n",
    "if test_data.shape[0] > test_labels.shape[0]:\n",
    "    test_data = test_data[:test_labels.shape[0]]\n",
    "\n",
    "# Verify the adjustment\n",
    "print(\"Adjusted train_data shape:\", train_data.shape)\n",
    "print(\"Adjusted test_data shape:\", test_data.shape)\n",
    "\n",
    "# Recreate the datasets and loaders\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating DataLoaders for efficient training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset = TensorDataset(train_data, train_labels)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "test_dataset = TensorDataset(test_data, test_labels)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading the Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_vectors = np.load('/Users/thzaamoun/Desktop/Academia/Fall 23/NLP/Assignment 2/VSCODE/full_grams_cbow_300_wiki/full_grams_cbow_300_wiki.mdl.wv.vectors.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRU Model Class-Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, num_embeddings, embedding_dim, hidden_dim, num_layers, dropout, bidirectional, num_classes):\n",
    "        super(GRUModel, self).__init__()\n",
    "        \n",
    "        # Define layers\n",
    "        self.embedding = nn.Embedding(num_embeddings, embedding_dim)\n",
    "        self.gru = nn.GRU(input_size=embedding_dim,\n",
    "                          hidden_size=hidden_dim,\n",
    "                          num_layers=num_layers,\n",
    "                          dropout=dropout if num_layers > 1 else 0,\n",
    "                          bidirectional=bidirectional,\n",
    "                          batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim * 2 if bidirectional else hidden_dim, 3)\n",
    "        \n",
    "        # Other layers and initialization can be added here\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x is your input data\n",
    "        embedded = self.embedding(x)\n",
    "        gru_out, _ = self.gru(embedded)\n",
    "        \n",
    "        # If the GRU is bidirectional, concatenate the final forward and backward hidden states\n",
    "        if self.gru.bidirectional:\n",
    "            gru_out = torch.cat((gru_out[:, -1, :self.gru.hidden_size], gru_out[:, 0, self.gru.hidden_size:]), dim=1)\n",
    "        else:\n",
    "            gru_out = gru_out[:, -1]\n",
    "\n",
    "        # Apply the fully connected layer and return its output\n",
    "        output = self.fc(gru_out)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Instanciation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embeddings = 114000\n",
    "model = GRUModel(num_embeddings=num_embeddings,  # Size of your vocabulary\n",
    "                 embedding_dim=300,     # Dimension of word embeddings\n",
    "                 hidden_dim=256,        # GRU hidden dimensions\n",
    "                 num_layers=2,          # Number of GRU layers\n",
    "                 dropout=0.5,           # Dropout rate\n",
    "                 bidirectional=True,    # Use a bidirectional GRU\n",
    "                 num_classes=3)         # Number of output classes (e.g., positive or negative)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Integrity of input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum index in train_data: tensor(57246)\n"
     ]
    }
   ],
   "source": [
    "# Check the maximum index in your input data\n",
    "max_index = train_data.max()\n",
    "print(\"Maximum index in train_data:\", max_index)\n",
    "\n",
    "# Ensure that this max index is less than num_embeddings\n",
    "assert max_index < model.embedding.num_embeddings, \"Index out of range. Increase num_embeddings in your model.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mode of Running The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GRUModel(\n",
       "  (embedding): Embedding(114000, 300)\n",
       "  (gru): GRU(300, 256, num_layers=2, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=512, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define Loss Function & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique label indices in the training dataset: {0, 1, 2}\n"
     ]
    }
   ],
   "source": [
    "unique_labels = set()\n",
    "for _, labels in train_loader:\n",
    "    labels = torch.argmax(labels, dim=1)\n",
    "    unique_labels.update(labels.tolist())\n",
    "print(\"Unique label indices in the training dataset:\", unique_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10  # Number of epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for inputs, labels in train_loader:\n",
    "        # Convert one-hot encoded labels to class indices if necessary\n",
    "        if labels.dim() > 1 and labels.size(1) > 1:\n",
    "            labels = torch.argmax(labels, dim=1)\n",
    "\n",
    "        # Filter out instances with label '3'\n",
    "        valid_indices = labels != 3\n",
    "        inputs = inputs[valid_indices]\n",
    "        labels = labels[valid_indices]\n",
    "\n",
    "        # Check if label '3' still exists in the batch\n",
    "        if labels.max() >= 3:\n",
    "            print(\"Error: Label '3' found in batch after filtering\")\n",
    "            continue  # Skip this batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        # Compute loss and backpropagate\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "# Ensure the model's final layer outputs 3 values for 3 classes\n",
    "assert model.fc.out_features == 3, \"Model's output layer should have 3 features\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mUntitled-1.ipynb Cell 52\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y100sdW50aXRsZWQ%3D?line=6'>7</a>\u001b[0m inputs, labels \u001b[39m=\u001b[39m batch\n\u001b[1;32m      <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y100sdW50aXRsZWQ%3D?line=7'>8</a>\u001b[0m inputs, labels \u001b[39m=\u001b[39m inputs\u001b[39m.\u001b[39mto(device), labels\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y100sdW50aXRsZWQ%3D?line=9'>10</a>\u001b[0m outputs \u001b[39m=\u001b[39m model(inputs)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y100sdW50aXRsZWQ%3D?line=10'>11</a>\u001b[0m _, predicted \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mmax(outputs\u001b[39m.\u001b[39mdata, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y100sdW50aXRsZWQ%3D?line=11'>12</a>\u001b[0m total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m labels\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "\u001b[1;32mUntitled-1.ipynb Cell 52\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y100sdW50aXRsZWQ%3D?line=16'>17</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y100sdW50aXRsZWQ%3D?line=17'>18</a>\u001b[0m     \u001b[39m# x is your input data\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y100sdW50aXRsZWQ%3D?line=18'>19</a>\u001b[0m     embedded \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membedding(x)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y100sdW50aXRsZWQ%3D?line=19'>20</a>\u001b[0m     gru_out, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgru(embedded)\n\u001b[1;32m     <a href='vscode-notebook-cell:Untitled-1.ipynb?jupyter-notebook#Y100sdW50aXRsZWQ%3D?line=21'>22</a>\u001b[0m     \u001b[39m# If the GRU is bidirectional, concatenate the final forward and backward hidden states\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/modules/sparse.py:162\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    161\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 162\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49membedding(\n\u001b[1;32m    163\u001b[0m         \u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding_idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_norm,\n\u001b[1;32m    164\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnorm_type, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale_grad_by_freq, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msparse)\n",
      "File \u001b[0;32m~/Library/Python/3.11/lib/python/site-packages/torch/nn/functional.py:2233\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2227\u001b[0m     \u001b[39m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2228\u001b[0m     \u001b[39m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m     \u001b[39m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2230\u001b[0m     \u001b[39m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2231\u001b[0m     \u001b[39m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[39minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2233\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49membedding(weight, \u001b[39minput\u001b[39;49m, padding_idx, scale_grad_by_freq, sparse)\n",
      "\u001b[0;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for batch in test_loader:\n",
    "        inputs, labels = batch\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f'Accuracy: {100 * correct / total}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save The Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text):\n",
    "    model.eval()\n",
    "    # Preprocess the text\n",
    "    # Convert text to tensor\n",
    "    # Forward pass\n",
    "    # Interpret the output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Pre-trained Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.embedding.weight = nn.Parameter(torch.tensor(pretrained_embeddings, dtype=torch.float32))\n",
    "model.embedding.weight.requires_grad = False  # Freeze the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
